%\section{Network Surgery}
%Network surgery is the technique of performing equivalent network transformations to eliminate redudant constraints required for synthesis of switch rules. One of the properties of the path found by the synthesis solver is that it is simple (i.e no loops). Using this property, we can create slices of the topology where a packet class' path will reside completely, thus not requiring to add constraints for switches in other slices of the topology. 
%
%To create the topology slices, we use Schmidt's linear-time algorithm\cite{schmidt} to find bridges in the graph. A bridge is an edge in the topology, which when removed, partitions the graph into two disconnected components. <write-about-slices>. 
%
%Consider a reachability policy where the source and destination switches belong to the same topology slice. Since, the bridge edge is the only edge connected vertices of this slice with the rest of the graph, the path for the reachability policy will be contained in the topology slice and not cross the bridge (otherwise the path would have to traverse through the bridge twice back and forth which is not permitted). 
%
%Formally, let us define the slices of the topology as $S_1$, $S_2, \ldots S_n \subset S$. We define the slice neighbour function for the slices as $N_{S_i}(s) = \{v | v \in S_i \wedge (s,v) \in L\}$. If there is a reachability policy $(r, pc)$ with $src,dst \in S_i$, we can replace the switch domain $S$ by $S_i$ and the neighbour function $N$ by $N_{S_i}$ in the constraint formation for reachability. For example, the backward reachability propagation constraints for a policy in slice $S_i$ can be modified to : 
%\begin{multline}
%\forall n_1,k.  n_1 \in S_i \wedge Reach(n_1,pc,k) \implies \exists n_2. n_2 \in N_{S_i}(n_1) \\ \wedge  Reach(n_2,pc,k-1) \wedge Fwd(n_2,n_1,pc)
%\end{multline}
%For packet classes isolated with packet class $pc$, only links in $S_i$ are needed to be isolated, as the path will be confined to topology slice $S_i$. 


\section{Divide-and-Conquer Synthesis} \label{sec:optimistic}
%\aditya{I haven't read earlier tech sections yet. we need to make sure ``packet class'' is defined somewhere, as it is an unusual term. also, we need to figure out how we are using ``policy''.}

One of the key challenges to the synthesis performance is the number
of packet classes synthesized and the policy interactions among them
(isolation, capacity, etc.). Since the complexity of finding a
forwarding plane configuration is roughly \emph{exponential} in the
number of packet classes, the synthesis time shoots up with increasing
packet classes. 
We notice that since datacenter topologies have a dense interconnection of
links between layers there can be
numerous different forwarding plane configurations as solutions.
% \aditya{previous sentence does not parse} 
We propose a heuristic approach which partitions the problem 
into smaller components to speed up synthesis.

The intuition is as follows, suppose we have two packet classes $pc_1,
pc_2$ isolated from one another, the standard synthesis algorithm adds 
constraints for both packet classes to the solver for finding the solution.
Instead, we could synthesize $pc_1$
independently and, after that, find a solution for $pc_2$ 
that is isolated from the
path obtained for $pc_1$. We term this
procedure \emph{divide-and-conquer} synthesis, as we divide
the problem and try to synthesize them separately.
However, synthesis of $pc_2$ can fail because the solution
of $pc_1$ may be such that there is no way to place an isolated path for
$pc_2$ but if they have been synthesized together, a
solution might exist. To improve effectiveness, we integrate the 
divide-and-conquer approach with recovery 
mechanisms discussed in \Cref{sec:recovery}

\begin{algorithm}[h]
\begin{footnotesize}
	\floatname{algorithm}{Pseudocode}
	\caption{Divide-and-Conquer Synthesis}
	\label{dcsyn}
	\begin{algorithmic}[1]
		\Procedure{DCSyn(P)}{}
		\If{$size(P) < P_{thres}$}
		\State{Apply normal synthesis on P}  
		\Else
		\State{Partition P into $P_1$ and $P_2$}
		\If{interpartition edges $> E_{thres}$} \State{Apply normal synthesis on P} \EndIf
		\State{F = []  \hspace{1cm} /* Failed solutions */}
		\State{attempts = 0} 
		\While{$attempts < RA_{max}$}
		\State{$sol_1$ = Apply  synthesis on $P_1$ such that $sol_1 \notin F$}
		\If{synthesis($P_1$) fails} \State{\Return DCSyn failure} \EndIf
		\State{$sol_2$ = Apply synthesis on $P_2$ such that \newline \hspace*{2cm} $sol_2 + sol_1$ is a solution for P}
		\If{synthesis($P_2$) fails} 
		\State{F.append(unsat-cores($P_2$))}
		\State{attempts++}
		\Else
		\State{\Return DCSyn success}
		\EndIf
		\EndWhile
		\State{\Return DCSyn failure}
		\EndIf
		\EndProcedure
	\end{algorithmic}
\end{footnotesize}
\end{algorithm}



%% $pc_1$ would have been different.

We define a policy graph $P = (R, I)$ where every vertex $r \in R$
is a packet class for a reachability/waypoint policy and edges
denote isolation constraints between packet classes.
%\aditya{again the
%  use of packet class and policy here is unconventional and needs to
%  be carefully defined early on} 
An edge $(r_1,r_2) \in I$  means that the paths of $r1$ and $r2$ are
isolated from each other. We assume that there are no capacity policies
in the input specifications. 
%since isolation is a local policy 
%in the sense that correct enforcement of isolation only requires information of neighbours
%\loris{don't know what this last sentence means}. 
%Resource managements policies like link capacity policies are global,
% and thus difficult to reason about them in smaller components.
  Given the policy graph $P$, we
can synthesize each connected component independently, since packet
classes in different connected components are not related by any
isolation policy, and therefore are independent of each other.

We describe the heuristic synthesis procedure in Pseudocode 1,
which takes as input a connected component of the policy graph.
 The crux of the procedure is that we partition each connected component $P$
  into two smaller components $P_1$ and $P_2$
  and do the following:
%   \aditya{are these
%  two connected components? if so, there will be no policy interaction
%  across them, no? given that, the following statement seems
%  incorrect} 
1) synthesize $P_1$ and obtain a solution $S_1$, and
2) for packet classes of $P_2$ that are
isolated to packet classes in $P_1$, 
%\aditya{this seems incorrect: no such packet classes exist?} 
add the solution $S_1$ as a constraint to ensure that the
packet classes in $P_2$ will not share the edges of the respective
paths obtained in $P_1$. 
%The difference from
%normal synthesis for a isolation policy is that since we don't have
%the paths for both packet classes, we add isolation constraints at all
%switches (\cref{eq:isolation})
%\loris{don't know what previous and next sentence means. Please rewrite clearly}. 
%In contrast, if we had a solution for
%one packet class, we need to ensure the other path is isolated only at
%the switches visited by the path of the solved packet
%class. 
%\aditya{it seems from the rest of the description below that p1
%  and p2 are not two connected components; they are just subgraphs. if
%  so, the ending sentence of the previous paragraph that talks about
%  connected components is misleading because that is not actually what
%  we do}
%\aditya{I did not look at the pseducode}

We use two schemes to partition the policy graph connected component into two: the
first one is \emph{min-cut} partitioning, which partitions the graph
such that inter-partition edge count is minimized. The
rationale behind the heuristic is that since we intend to perform the
synthesis of both partitions separately, the partition should maximize
the isolation policies within components and minimize across
components. By maximizing isolation policies during synthesis of the
component, the partial solution is more likely to be compatible with a
complete solution. However, if the min-cut partitioning produces a
component smaller than a threshold size, we perform partitioning of
the graph into two equal sized partitions and minimizing the cut edges
between the partitions. We need to ensure that we don't partition the
graph smaller than a threshold, as the partial solutions obtained by
synthesis of very small partitions are more likely to conflict with
other packet classes. Our implementation of \Name performs
divide-and-conquer synthesis recursively on the components till we cannot partition the
component further. 

\subsection{Solution Recovery} \label{sec:recovery}
While in the best case divide-and-conquer synthesis  will lead to a great
increase in performance, we need a recovery mechanism in case we cannot find
compatible partial solutions.  We describe a bounded \emph{solution} recovery
scheme in \Cref{dcsyn}(lines 17-19) integrated with the divide-and-conquer
synthesis procedure.  The Z3 solver can track assertions and if it
fails to find a solution, it can return a set of unsatisfiable cores
which are the assertions due to which the solver could not find a
solution\footnote{Z3 does not return the minimum set of unsatisfiable
  cores.}.  This helps us track failed partial solutions so that we 
don't resynthesize them again. 
%  in the synthesis of $P_2$
%by tracking the constraints added to ensure isolation with the paths
%of $P_1$.  
Thus, if synthesis of $P_2$ fails, the unsatisfiable cores
obtained from Z3 will be the paths of the solution of $P_1$ which are
causing the synthesis of $P_2$ to fail. 
When performing synthesis of $P_1$
again, we therefore ensure that we get \emph{different} paths from the
unsatisfiable cores we extracted.  Basically, we perform a 
\emph{solver-guided} enumeration of different solutions of $P_1$ to
find a satisfying solution for $P_2$ for faster convergence.

There are drawbacks to performing recovery. Since, recovery is a 
form of enumeration, in cases where the graph is highly constrained
(clique), finding a solution can lead to increased number of enumerations,
while synthesis without partitioning would provide a solution faster. 
Thus, we bound the number of enumerations performed by the 
recovery mechanism and return failure to find a solution by solution recovery
if we don't obtain a solution. 

Divide-and-conquer synthesis with recovery is sound, but 
it is incomplete as we bound the
number of enumerations. The success of this approach
is directly related to the size of the components (determined by $P_{thres}$). 
This is because, by synthesizing more packet classes together, we decrease the
conflicts arising between partial solutions. The extreme case is when we do not 
partition the component at all (normal synthesis), which is complete. 
Thus, to make the synthesis complete with faster convergence, we
perform iterations of divide-and-conquer synthesis, and at each iteration we double the
partition threshold $P_{thres}$ if the previous iteration failed. 
% \aditya{when is this doubling done? during one of the
%	recursive invocations, or only at the beginning?} 
This scheme tries to balance the trade-off between completeness, which
requires larger components, and performance, as synthesis is faster on smaller
components. 
In the extreme case, after $O(log~P)$
iterations, $P_{thres} > P$ and the divide-and-conquer synthesis routine cannot partition the graph any further,
thus rendering the routine complete. 
% \aditya{I
%	don't see this. you may not find a solution, no?}. In the extreme
%case, $P_{thres} \geq P$ and the algorithm will perform normal
%synthesis, and thus become complete. In a case when this happens
%\aditya{this is vague. what does ``this'' mean? are you saying
%	whenever doubling happens perf is degraded? if so, why do it?}, the
%performance of optimistic synthesis is degraded.
%However, synthesizing $P$ completely
%without partitioning would be faster than performing optimistic
%synthesis (densely connected like a clique) and enumerating as it
%would fail more often \aditya{this sentence is wierd. are you trying
%  to say that synthesizing P is faster in *some* cases?}. Thus, we
%bound the number of recovery attempts to ensure that we can say that
%optimistic synthesis has failed and perform normal
%synthesis. \aditya{need to be precise. what does ``to ensure that we
%  can say...'' mean}
 
 This synthesis approach is more \emph{effective}
 when there is a large number of solutions and provides a
 significant improvement. When the problem is highly 
 constrained and the number of solutions is low, 
 the recovery mechanisms and multiple iterations could 
 lead to a degraded performance. 
% by the optimistic synthesis 
% routine. 
 We evaluate the performance improvement of divide-and-conquer
 synthesis with varying isolation workloads in \Cref{sec:optimisticeval}.
 One of the major drawbacks of the divide-and-conquer approach is that it is very
 difficult to apply to global policies (like traffic engineering) primarily because
 there isn't a easy way to split the problem, and development
 of heuristics for global policies is a direction of future work.

 %\aditya{the last para was very vague. rest of the section was OK, modulo my comments}
 
%
