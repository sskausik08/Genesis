\section{Synthesising Domain Assignments}
\label{sec:synth-dom-ass}

In this section, we present an algorithm for 
solving the path-compliance when a domain assignment is not given to us.
The algorithm searches the space of possible domain assignment $\Theta$ to find
one that meets all configuration policies and has good quantitative properties.
In particular, we will focus our discussion on maximizing resiliency while minimizing
configuration overhead---e.g., number of static routes and BGP configuration variables. 

Formally, we are given a set of paths $\Pi$,
a topology $T=(V,L)$,
a domain-assignment function $\Theta$ such that $|\{\Theta(r) \mid r\in V\}|>1$, 
and we want to find functions
$LP$, $W$, $RF$,  and $\Theta$ such that
$C=(T,W,RF,LP,\Theta)$ and
$\paths^C(PC) = \Pi$.
We call this problem the \emph{domain placement problem}.

\loris{all definitions are missing static routes, please fix}
We first show that even the simplest variant of the domain assignment problem,
in which route filters are disallowed, is NP-complete.
\begin{theorem}
Given a set of paths $\Pi$,
a topology $T=(V,E)$, 
a route-filter function $RF$ such that $\sum_{r\in V} |RF(r)|=0$,
the problem of finding 
a domain assignment $\Theta$, 
a local preference function $LP$,
and edge weights $W$
 such that
$C=(T,W,RF,LP,\Theta)$ and
$\paths^C(PC) = \Pi$  is NP-complete.
\loris{messy}
\end{theorem}

Given the complexity of this problem, we opt for a greedy
(\kausik{stochastic?}) approach
to  search the space of domain
assignments. 
\name uses Markov
Chain Monte Carlo (MCMC) sampling methods, specifically the Metropolis-Hasting
algorithm, a common technique used in different optimization 
problems~\cite{stoke}. 
We first present the general structure of our searching algorithm and 
then describe the cost function we use to guide the search.

\subsection{Searching Assignments with MCMC}
MCMC sampling is a technique for 
drawing elements from a
probability density function in direct proportion to its value.
%Intuitively, the search samples regions of higher probability more often than 
%regions of low probability. 
Intuitively, the probability distribution can be viewed as a (potentially infinite) 
connected undirected graph
where nodes are elements of the probability distributions
and edges denotes possible next steps in the search---i.e.,
which nodes we can visit next.
Each node is associated with a cost so that nodes with higher costs have lower
probabilities associated with them.

In our case, each node is a domain assignment $\Theta$
with some cost $c(\Theta)$. 
We will discuss how our cost function is implemented in the next sections.
The cost function $c$ can be transformed 
into a probability density function in the following way~\cite{mcmcbook}:
\begin{equation}
	p(\Theta) = \frac{1}{Z}exp(-\beta * c(\Theta))
\end{equation}
where $\beta$ is a positive constant and $Z$ is a partition function \loris{over what?} that
normalizes the distribution. Computing $Z$ is in general 
intractable, and the Metropolis-Hasting algorithm 
explores the search graph representing $p$ without computing the partition function. 
Intuitively, given a current domain
assignment $\Theta$, the algorithm proposes a modified 
domain assignment as the next step  by picking a neighbour
$\Theta'$ of $\Theta$ in the graph. A coin is then toss with
probability 
\begin{equation}
Pr(\Theta \rightarrow \Theta') = min(1, \frac{p(\Theta')*q(\Theta| \Theta')}{p(\Theta)*q(\Theta'| \Theta)})
\end{equation}
If the result is head, $\Theta'$
becomes the current node, otherwise $\Theta$ remains the current node.
$q(\Theta'| \Theta)$ denotes the proposal distribution from 
which $\Theta'$ is chosen given $\Theta$. If the proposal 
distributions is symmetric, i.e., 
$q(\Theta| \Theta') = q(\Theta'| \Theta)$, then the acceptance
probability is reduced to the simpler Metropolis ratio, which
can be computed directly from the cost function $c(\Theta)$:
\begin{multline}
Pr(\Theta \rightarrow \Theta') = min(1, \frac{p(\Theta')}{p(\Theta)}) \\
= min(1, exp(-\beta.(C(\Theta') - C(\Theta)))
\end{multline}
The algorithm will always accept a new proposal $\Theta'$
that has cost lower than $\Theta$. If $\Theta'$ has a 
higher cost than $\Theta$, the proposal will be 
accepted with probability depending on 
how far the costs of $\Theta$ and $\Theta'$ are. This ensures that 
the algorithm does not get stuck at local minimas, but 
explores proposals with smaller differences in cost with 
higher probability. We describe the MCMC search procedure 
in Pseudocode~\cref{alg:mcmc}. 


\begin{algorithm}[t]
	\floatname{algorithm}{Pseudocode}
	\caption{MCMC}
	\label{dcsyn}
	\begin{algorithmic}[1] \label{alg:mcmc}
		\Procedure{MCMCSearch}{}
		\State{$\Theta \leftarrow$ random domain assignment}
		\State{$\overline{cc} = 0$ \hspace{2cm} [Worst Conf. overhead]}
		\State{$\overline{rc} = 0$ \hspace{2cm} [Worst route-filter est.]}
		\While{max iterations OR timeout}
		\State{$\gamma$ = \Call{Cost}{$\Theta$}}
		\State{$\Theta'$ = \Call{RandomChange}{$\Theta$}}
		\State{$\gamma'$ = \Call{Cost}{$\Theta'$}}
		\State{$Pr(\Theta \rightarrow \Theta')$ = 
			min$(1, exp(-\beta.(\gamma' - \gamma))$}
		\State{Set $\Theta$ = $\Theta'$ with 
			probability $Pr(\Theta \rightarrow \Theta')$}
		\EndWhile
		\EndProcedure
		
		\Procedure{Cost}{$\Theta$} 
		\State{$cc \leftarrow$ Configuration overhead (Static routes + \newline \hspace*{1.5cm} 
			BGP local preference entries + iBGP filters)}
		\If{$cc > \overline{cc}$} 
		\State{$\overline{cc} = cc$}
		\EndIf
		\State{$rc \leftarrow$ Number of diamonds with  \newline 
			\hspace*{1.3cm}  endpoints in same domain }
		\If{$rc > \overline{rc}$} 
		\State{$\overline{rc} = rc$}
		\EndIf
		\State{$\gamma$ = max($cc/\overline{cc},
			\alpha.rc/\overline{rc}$)  \newline
			\hspace*{3.5cm} + 0.1*min($cc/\overline{cc},
			\alpha.rc/\overline{rc}$)}
		\State{\Return $\gamma$}
		\EndProcedure
		
		\Procedure{RandomChange}{$\Theta$}
		\While{True}
		\State{$r \leftarrow$ pick random boundary router}
		\State{$\theta \leftarrow$ pick random neighbouring domain of $r$}
		\If{$|\Theta(r)| - 1 \geq l_\Theta \wedge |\theta| + 1 \leq u_\Theta$}
		\State{$\Theta' \leftarrow \Theta[r \rightarrow \theta]$} \hfill [$r$'s domain changed to $\theta$]
		\If{domains are continous}
		\State{\Return $\Theta'$}
		\EndIf
		\EndIf
		\EndWhile
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

\subsection{Domain Assignment Cost}
In the previous section, we presented the general structure of our search algorithm,
but we did not specify how the cost function $c(\Theta)$
is computed. Intuitively, the cost function should capture
how far we are from meeting all the given control-plane policies.
For example, if we are trying to obtain good resiliency,
domain assignments with better resiliency should have lower costs.
Similarly, a configuration with lower number of static routes is better
than one with more number of static routes. Therefore, we also consider 
the configuration overhead in terms of static routes and BGP configuration
variables in our cost function.
The techniques presented in Section~\ref{sec:synth-multi} provide a way to 
synthesize a configuration for each domain assignment and therefore compute
very precise costs for each domain assignment. 
However, 
we want MCMC to explore as many assignments as possible,
therefore 
synthesizing the actual configurations for
each domain assignment is infeasible (Theorem~\ref{thm:ospfsynth} shows that, 
even for a single domain, computing accurate costs---e.g., 
number of required route filters---is an NP-complete problem).


\minisection{Approximating number of route filters}
We present a technique for over-approximating the number of route 
filters required by a particular domain assignment and use this 
to estimate the resiliency of a domain assignment---i.e., a domain assignment with fewer 
route-filters is likely to have higher resiliency. 

\loris{in preliminaries early on define that we use $l\in\pi$ to say path $\pi$ contains a link $l$.}

We say that two paths $\pi=(r_1,r_2)\cdots (r_{n-1},r_n), \pi'=(r_1',r_2')\cdots (r_{n-1}',r_n')$ with destinations $\lambda$ and $\lambda'$
form an $(r_i, r_j, \lambda, \lambda')$\emph{-diamond} if and only if
there exists $i,i',j$, and $j'$ such that $i<j-1$, $i'<j'-1$, and
\begin{multline}
r_i{=}r_{i'}' \wedge  r_j{=}r_{j'}' \wedge  \forall i{<}k{<}j.~\forall i'{<}k'{<}j'.~r_{k}{\neq} r_{k'}'  
\end{multline}
Intuitively, a diamond is the smallest structure formed by two
paths intersecting at $r_i$ and $r_j$ with edge-disjoint paths in 
between these routers. 
As a diamond 
implies there are two unique shortest paths between $r_s$ and $r_t$,
atleast one route-filter is required.

However, if $r_s$ and $r_t$ of the diamond lie in
different domains, the inconsistent paths would be split 
across domains, and \name can find OSPF weights for
both the domains without route-filters (in the case if this
diamond was the only source of inconsistency). In the limiting
case where each router is a separate domain of size 1,
no route-filters are required, and the entire 
network can be configured using BGP. 

Before \name starts the MCMC search, it undergoes a preprocessing phase 
where for every pair of input paths, it identifies the
number of diamonds created by the path 
and store the start and end router of 
each diamond. In a MCMC iteration based on the current 
domain assignment $\Theta$, for every diamond, we check if 
$\Theta(r_s) = \Theta(r_t)$. If yes, 
we assume one filter for this particular
diamond is required and increment the route-filter cost by 1. The 
route-filter cost is not incremented if the start and end 
router of the diamond belong in different domains in $\Theta$.

The cost computed by the above procedure overestimates the
number of route-filters required to eliminate the diamonds.  
Two different diamonds sharing an edge could be both 
eliminated by a single filter, whereas our route-filter cost 
would be 2. However, there are path fragments which 
lead to inconsistencies, but are not diamonds, and thus
are not included in the route-filter cost. However, the 
cost can be computed efficiently every iteration, and 
our experiments show reductions in route-filter cost 
lead to reductions in number of filters(~\Cref{some experiment}). 

\minisection{Cost of Configuration Overhead} 
Finding the actual number of static routes, and 
BGP local preferences and iBGP filters can be performed 
efficiently (\Cref{sec:synth-multi}), therefore, 
configuration cost = Count of Static Routes + Count of 
BGP local preferences + count of iBGP filters 
(for all destinations)\footnote{
	Operators can specify relative weights of each overhead, for e.g.--an
	operator may want to reduce only static routes.}.

\minisection{Overall Cost Function} 
Route-Filter cost ($rc$) and Configuration cost ($cc$) 
are inversely related. In the limiting cases,
if the whole network was a single OSPF domain,$rc$ is maximum, while
$cc$ is 0. Similarily, Conf-Cost is maximum when all routers are a
separate domain. Therefore, to jointly optimize these quantities, we
consider the $max(RC, \alpha*CC)$ where $\alpha$ is a tunable parameter
to assign importance to different objectives. We normalize
both costs by dividing them by the worst cost seen during the MCMC,
thereby, the ratio is the improvement of the best configuration over
the worst in terms of either configuration overhead or route-filter cost.