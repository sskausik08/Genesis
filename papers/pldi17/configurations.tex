\section{Synthesising Domain Assignments}
\label{sec:synth-dom-ass}

In this section, we describe how \name searches the space of possible
domain assignments $\Theta$.
The goal of this search is to find a domain assignment for which
the techniques presented in Section~\ref{} can find weights, route filters,
BGP preferences, and static routes that satisfy all the given \loris{control-plane?} policies..
In particular, we will focus our discussion on maximizing resiliency while minimizing
configuration overhead---e.g.,  number of LoC and route-filters.

We first show that even the simplest variant of \loris{what problem} is NP-complete.
\begin{theorem}
\loris{what is the problem that is NP-complete}
\end{theorem}
Given the complexity of this problem, \name  searches the space of domain
assignments Markov
Chain Monte Carlo (MCMC) sampling methods, specifically the Metropolis-Hasting
algorithm, a common technique used in different optimization 
problems~\cite{stoke}. 
We first present the general structure of our searching algorithm and 
then describe the cost function we use to guide the search.

\subsection{Searching Assignments with MCMC}
MCMC sampling is a technique for 
drawing elements from a
probability density function in direct proportion to its value.
%Intuitively, the search samples regions of higher probability more often than 
%regions of low probability. 
Intuitively, the probability distribution can be viewed as a (potentially infinite) 
connected undirected graph
where nodes are elements of the probability distributions
and edges denotes possible next steps in the search---i.e.,
which nodes we can visit next.
Each node is associated with a cost so that nodes with higher costs have lower
probabilities associated with them.

In our case, each node is a domain assignment $\Theta$
with some cost $c(\Theta)$. 
We will discuss how our cost function is implemented in the next sections.
The cost function $c$ can be transformed 
into a probability density function in the following way~\cite{mcmcbook}:
\begin{equation}
	p(\Theta) = \frac{1}{Z}exp(-\beta * c(\Theta))
\end{equation}
where $\beta$ is a positive constant and $Z$ is a partition function \loris{over what?} that
normalizes the distribution. Computing $Z$ is in general 
intractable, and the Metropolis-Hasting algorithm 
explores the search graph representing $p$ without computing the partition function. 
Intuitively, given a current domain
assignment $\Theta$, the algorithm proposes a modified 
domain assignment as the next step  by picking a neighbour
$\Theta'$ of $\Theta$ in the graph. A coin is then toss with
probability 
\begin{equation}
Pr(\Theta \rightarrow \Theta') = min(1, \frac{p(\Theta')*q(\Theta| \Theta')}{p(\Theta)*q(\Theta'| \Theta)})
\end{equation}
If the result is head, $\Theta'$
becomes the current node, otherwise $\Theta$ remains the current node.
$q(\Theta'| \Theta)$ denotes the proposal distribution from 
which $\Theta'$ is chosen given $\Theta$. If the proposal 
distributions is symmetric, i.e., 
$q(\Theta| \Theta') = q(\Theta'| \Theta)$, then the acceptance
probability is reduced to the simpler Metropolis ratio, which
can be computed directly from the cost function $c(\Theta)$:
\begin{multline}
Pr(\Theta \rightarrow \Theta') = min(1, \frac{p(\Theta')}{p(\Theta)}) \\
= min(1, exp(-\beta.(C(\Theta') - C(\Theta)))
\end{multline}
The algorithm will always accept a new proposal $\Theta'$
that has cost lower than $\Theta$. If $\Theta'$ has a 
higher cost than $\Theta$, the proposal will be 
accepted with probability depending on 
how far the costs of $\Theta$ and $\Theta'$ are. This ensures that 
the algorithm does not get stuck at local minimas, but 
explores proposals with smaller differences in cost with 
higher probability. We describe the MCMC search procedure 
in Pseudocode~\cref{alg:mcmc}. 


\begin{algorithm}[t]
	\floatname{algorithm}{Pseudocode}
	\caption{MCMC}
	\label{dcsyn}
	\begin{algorithmic}[1] \label{alg:mcmc}
		\Procedure{MCMCSearch}{}
		\State{$\Theta \leftarrow$ random domain assignment}
		\State{$\overline{cf} = 0$ \hspace{2cm} [Worst Conf. overhead]}
		\State{$\overline{rf} = 0$ \hspace{2cm} [Worst route-filter est.]}
		\While{max iterations OR timeout}
		\State{$\gamma$ = \Call{Cost}{$\Theta$}}
		\State{$\Theta'$ = \Call{RandomChange}{$\Theta$}}
		\State{$\gamma'$ = \Call{Cost}{$\Theta'$}}
		\State{$Pr(\Theta \rightarrow \Theta')$ = 
			min$(1, exp(-\beta.(\gamma' - \gamma))$}
		\State{Set $\Theta$ = $\Theta'$ with 
			probability $Pr(\Theta \rightarrow \Theta')$}
		\EndWhile
		\EndProcedure
		
		\Procedure{Cost}{$\Theta$} 
		\State{$cf \leftarrow$ Configuration overhead (Static routes + \newline \hspace*{1.5cm} 
			BGP local preference entries + iBGP filters)}
		\If{$cf > \overline{cf}$} 
		\State{$\overline{cf} = cf$}
		\EndIf
		\State{$rf \leftarrow$ Number of diamonds with  \newline 
			\hspace*{1.3cm}  endpoints in same domain }
		\If{$rf > \overline{rf}$} 
		\State{$\overline{rf} = rf$}
		\EndIf
		\State{$\gamma$ = max($cf/\overline{cf},
			\alpha.rf/\overline{rf}$)  \newline
			\hspace*{3.5cm} + 0.1*min($cf/\overline{cf},
			\alpha.rf/\overline{rf}$)}
		\State{\Return $\gamma$}
		\EndProcedure
		
		\Procedure{RandomChange}{$\Theta$}
		\While{True}
		\State{$r \leftarrow$ pick random boundary router}
		\State{$\theta \leftarrow$ pick random neighbouring domain of $r$}
		\If{$|\Theta(r)| - 1 \geq l_\Theta \wedge |\theta| + 1 \leq u_\Theta$}
		\State{$\Theta' \leftarrow \Theta[r \rightarrow \theta]$} \hfill [$r$'s domain changed to $\theta$]
		\If{domains are continous}
		\State{\Return $\Theta'$}
		\EndIf
		\EndIf
		\EndWhile
		\EndProcedure
	\end{algorithmic}
	
\end{algorithm}



\subsection{Domain Assignment Cost}
In the previous section, we presented the general structure of our search algorithm,
but we did not specify how the cost function $c(\Theta)$
is computed. Intuitively, the cost function should capture
how far we are from meeting all the given control-plane policies.
For example, if we are trying to obtain good resiliency,
domain assignments with better resiliency should have lower costs.
The techniques presented in Section~\ref{sec:synth-multi} provide a way to 
synthesize a configuration for each domain assignment and therefore compute
very precise costs for each domain assignment. However, 
we want MCMC to explore as many assignments as possible
running these techniques for
each domain assignment is infeasible (Theorem~\ref{} shows that, even for a single domain, computing accurate costs---e.g., number or
required route filters---is an NP-complete
problem).

\loris{unclear what the cost will be, is this only about resiliency?}

In this section, we propose techniques for approximating the cost of a domain assignment 
by exploiting topological properties of the network and the domains.
We first \loris{TODO}
and then \loris{TODO}.

\todo{Explain path, as\_path transformation more formally}


\begin{figure}
	\centering
	\begin{tikzpicture}[shorten >=0.5pt,node distance=,on grid,auto,
	square/.style={regular polygon,regular polygon sides=4}] 
	\node[state] at (0,0) [fill=yellow] (s)  {$s$}; 
	\node[state] at (2,0.5) (v1)  {$r_1~~~~$}; 
	\node[state] at (2,-0.5) (u1) {$r_2~~~~$}; 
	\node[state, fill=black!30!green] at (4, 0)(t) {$t$};
	\path[->] 
	(s) edge  node {} (v1)
	edge  node {} (u1)
	edge [blue, dashed, bend right=45] node {} (t)
	edge [red, dashed, bend left=45] node {} (t)
	(u1) edge node {} (t)
	(v1) edge node {} (t);
	\path[-] (u1) edge [dashed] node[above] {} +(0,2);
	\path[-] (v1) edge [dashed] node[above] {} +(0,-2);
	\end{tikzpicture}
	\caption{Diamond}
	\label{fig:diamonddomain}
\end{figure}


\paragraph{Approximating number of route filters}
We present a technique for \loris{over-approximating?} the number of route 
filters required by a particular domain assignment.
\loris{2 lines of intuition, need to finish previous section first to have notation}

If a diamond created by the input paths (\Cref{fig:diamonddomain}),
\name requires a route-filter to find a solution to OSPF
edge weights. However, if $s$ and $t$ of the diamond lie in
different domains, the inconsistent paths would be split 
across domains, and \name can find OSPF weights for
both the domains without route-filters (in the case if this
diamond was the only source of inconsistency). In the limiting
case where each router is a separate domain~\cite{bgpdatacenter}, 
we do not require any OSPF route-filters, and the entire 
network can be configured using BGP. Thus, a clever domain
assignment can also be reduce the number of route-filters, and
increase the resilience of paths. 


The process of finding the exact static and BGP configurations
required to induce the input paths has polynomial time complexity,
and thus can be found efficiently in every iteration of the MCMC
sampling. To minimize the number of route-filters, we can consider 
the number of route-filters for a given domain assignment $\Theta$ 
as one component of the cost function, and thus MCMC will try
to minimize the cost function, and consequently, the number of
filters. However, finding the optimal number of route-filters for a given domain assignment is NP-hard (\secref{sec:rfcomplexity}), thus, \name
cannot find the exact number of filters for each iteration to use for
the cost function. 

Instead, \name estimates the number of route-filters required for a 
particular domain assignment $\Theta$ for the cost function. Before 
we start the MCMC search, we undergo a preprocessing phase 
where for every pair of input paths, we identify the
number of diamonds created by the path (\todo{define diamond 
	formally somewhere}) and store the start and end router of 
each diamond. In a MCMC iteration based on the domain
assignment $\Theta$, for every diamond, we check if the
start and end router are part of the same domain. If yes, 
we assume we require atleast one filter for this particular
diamond and increment the route-filter cost by 1. The 
route-filter cost is not increment if the start and end 
router of the diamond belong in different domains in $\Theta$.

The cost computed by the above procedure overestimates the
number of route-filters required to eliminate the diamonds.  
Two different diamonds sharing an edge could be both 
eliminated by a single filter, whereas our route-filter cost 
would be 2. However, there are path fragments which 
lead to inconsistencies, but are not diamonds, and thus
are not included in the route-filter cost. However, the 
cost can be computed efficiently every iteration, and 
our experiments show reductions in route-filter cost 
lead to reductions in number of filters(~\Cref{some experiment}). 
\todo{Specify weird Route filter case without diamonds?}

\paragraph{Approximating number of static routes}
\loris{TODO, need notation from previous section}
