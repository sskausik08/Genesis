%!TEX root = paper.tex
\section{Problem Definition}
In this section, we formally define the problems addressed in this
paper.  We first describe the representation of different
routing protocols; we model static
routes, OSPF shortest-path routing, and BGP preference-based routing.
Then, we define what it means for a configuration to meet a given
set of policies and present the configuration synthesis problems
we tackle.
Finally, we formalize two resilience metrics called 
connectivity-resilience and policy-resilience; the goal 
of \name is optimizing these metrics. 

\subsection{Routing Model} \label{sec:routingmodel}

We represent the physical router topology as a directed graph $T=(V, L)$,
where $V$ is the set of routers and $L\subseteq V\times V$ is the set of links. 
Throughout the paper we assume $T$ is fixed.
We use the neighbour function $N(s) = \{s'\ | \ (s,s') \in L \}$ to denote 
the set of neighbour routers of $s$. 
A path $\pi = (r_1,r_2) (r_2, r_3) \cdots (r_{n-1}, r_n) \in L^*$ is a 
loop-free valid path if
a router is not visited more than once, denoted by $valid(\pi)$.
We also represent the path $\pi$ as 
$r_1\rightarrow r_2 \rightarrow  \cdots \rightarrow r_n$.
We write $l \in \pi$ when the path $\pi$ contains the link $l$. 
We define $\Lambda \subset IP$ to denote the set of 
destination IP addresses;
distributed protocols make forwarding decisions based on the 
destination address/subnet.

Hierarchical control planes partition the
network into multiple connected components called domains. 
We define a router domain assignment function
$\Theta: V \mapsto \nat$ which maps each router to a domain 
(denoted by a number). In this paper, we assume 
each domain uses OSPF as the intra-domain routing protocol
and BGP as the inter-domain routing protocol. We summarize
the notations in \Cref{tab:zeppelinconfig}. 

% In the 
%rest of the section, we describe each component 
%of the configuration $C$ and the routing function 
%$\route^C: V \times \Lambda \mapsto 2^V$ for 
%the network given the configuration $C$. 
%\kausik{Remove this simplifying assumption
%We assume the following  
%simplifying property for $C$: for any two 
%routers $r_1$ and $r_2$,
%traffic will be forwarded from $r_1$ to $r_2$ 
%along a single path. 
%When synthesizing $C$, we will ensure that this property is satisfied.}

\begin{figure}
\vspace{-2mm}
\small
\begin{minipage}{\linewidth}
	\begin{tabular}{m{9em}  m{18em} } 
		{\bf Term} & {\bf Description} \\ 
		\hline
		$T=(V,L)$ & Topology $T$ of routers $V$ and links $L$ \\ \hline
		$\Theta(r) = \theta$ & Router r belongs to domain $\theta$ \\ \hline
		$SR(r,\lambda)=\{r_1\}$ & Static route $r \rightarrow r_1$ for destination $\lambda$ \\ \hline
		$W(r_1, r_2)$ & OSPF weight of link $r_1 \rightarrow r_2$ \\ \hline
		$D(r_1, r_2)$ & Shortest OSPF distance from $r_1$ to $r_2$ \\ \hline
		$G(\theta, \lambda) = \{g_1, g_2\}$ & Set of exit gateway routers for $\lambda$ in domain $\theta$ \\ \hline
		$LP(r, r', \lambda)$ &  Local preference at $r$ to choose $r'$ route to $\lambda$ \\ \hline
		$IF(r_2, \lambda) = \{r_1\}$ & $r_2$ will not advertise $\lambda$ to $r_1$ using iBGP 
	\end{tabular}
	\end{minipage}
\compactcaption{Different configuration parameters in \name}
	\label{tab:zeppelinconfig}
\end{figure}


\minisection{Static Routes} 
These are statically configured next-hop routes with higher 
priority over those routes computed by OSPF and BGP.

\minisection{OSPF} In Open Shortest Path First (OSPF) routing,
traffic from a router $r$ to a destination $\lambda$ is forwarded across 
the shortest path from $r$ to $\lambda$.
We define the OSPF routing function $\route_{ospf}: 
V \times \Lambda \mapsto 2^V$ so that
$\route_{ospf}(r,\lambda)$ describes the next-hop for
router $r$ which lies on the shortest path for a destination $\lambda$. 
\iffull
Suppose $\lambda$ is directly connected to a router $r_\lambda$ 
in the same OSPF domain as $r$.
\begin{multline*}
\route_{ospf}(r,\lambda) = \{r_1 ~|~ r_1 \in N(r)~\wedge~ \forall r_2 \in N(s). \\ ~W(r, r_1) + D(r_1, r_\lambda) \le 
W(r, r_2) + D(r_2, r_\lambda)\}
\end{multline*}
\fi

\minisection{BGP} BGP is a path-vector inter-domain routing protocol
that connects different domains (or ASes).  
% (also called autonomous systems), where each domain
% comprises of one or more routers typically managed by a single
% entity. A BGP router receives routes from BGP peers: internal peers
% send iBGP routes, external peers send eBGP routes. Each route for 
% a certain
% destination comprises of a domain-level path to the destination
% domain and, by default, a BGP router will forward a packet through the path that traverses fewer domains.
BGP routers can be configured with a
local preference (LP)
to assign higher priorities to
specific routes for a 
particular destination. 
The Internal BGP (iBGP) protocol is used to 
exchange external BGP routes 
among BGP routers belonging
to the same domain. 
Informally, iBGP propagates local 
preferences of the routes to all the BGP 
routers within the same domain. 
We can configure iBGP 
filters (IF) to prevent a router from advertising 
a route. 

\iffull
\input{bgp-routing-algorithm} 
Algorithm~\ref{alg:bgppathrules} defines the BGP routing function
based on the best path selection at each BGP router. 
\fi
%a local preference function $LP$,
A BGP router receives eBGP and iBGP routes; it  
chooses a route with highest local preference, 
and if there is a tie, it chooses the route that traverses 
fewer domains~\cite{bgp}. 
We assume all ties 
are broken using these criteria. After route selection, 
if a eBGP route is preferred, the route is redistributed to OSPF.
Therefore, for a domain $\theta$, only BGP routers which
redistribute routes for destination $\lambda$ to OSPF  
belong to the gateway router set $G(\theta, \lambda)$.
We define a partial BGP routing function 
$\route_{bgp}: V \times \lambda \mapsto V$
such that
$\route_{bgp}(r,\lambda)$
describes the next-hop BGP router for the BGP
router $r$ when forwarding traffic for a destination $\lambda$. 


\minisection{OSPF+BGP+SR} We now describe how routing
happens in hierarchical networks with all the previously described protocols
used together.
We express the complete network configuration $C$
as a tuple $(T, \Theta,W,LP,IF,SR)$.
We define the routing function 
$\route^C: V \times \Lambda \mapsto 2^V$ 
so that
$\route^C(r,\lambda)$
 describes the next-hop router for the 
router $r$ when forwarding traffic for a destination $\lambda$. 
The priority order based on administrative distance~\cite{admindistance} is 
SR $>$ BGP $>$ OSPF. 
\iffull
The modified OSPF routing 
function $\route^C_{ospf}$ for an external destination $\lambda$
is defined as follows: 
\begin{multline*}
\route_{ospf}^C(r,\lambda) = \{~~r_1 \mid r_1 \in N(r) \wedge \exists g_1 \in G (\theta, \lambda). ~\forall r_2 \in N(s), \\ g_2 \in G (\theta, \lambda). ~W(r, r_1) + D(r_1, g_1) \leq
W(r, r_2) + D(r_2, g_2)\}
\end{multline*}
\fi
Piecing together the different routing protocols and their 
interactions, the routing function 
$\route^C$ for the hierarchical domain network configuration $C$ is defined as follows: 
\[
\route^C(r, \lambda) = 
\begin{cases}
SR(r, \lambda) & \text{if } SR(r, \lambda) \not= \emptyset, \\
\route_{bgp}^C(r, \lambda) & \text{if }r \in G(\Theta(r), \lambda), \\
\route_{ospf}^C(r, \lambda) & \text{otherwise.} 
\end{cases}
\]
%\[
%\begin{array}{c}
%	\route^C(s_1, t, \lambda) = 
%	\route_{ospf}^C(s_1,g_1, \lambda) + 
%	 (g_1, s_2 )+\qquad\qquad\qquad  \\
%%	~~~~~~~~~~~~~~~~~~~~~~~~~\route_{ospf}^C(s_2,g_2, \lambda) + (g_2, s_3) + \\
%	\qquad\qquad\qquad\qquad \cdots  + (g_{n-1}, s_n) +\route_{ospf}^C(s_n,t,\lambda)
%\end{array}
%\]

\minisection{Induced paths}
In the following, we assume a finite set of packet classes $PC = \{0, \ldots, C_{pc}\}$ 
and map each reachability
policy that requires the existence of a path between two endpoints
to a unique integer in $PC$. The rest of the policies specify 
properties on these paths. Each packet class $pc$ is associated
with a tuple ($s_{pc}, d_{pc}, \lambda_{pc})$ which specifies 
the path from $s_{pc}$ to $d_{pc}$ for destination IP $\lambda_{pc}$.

\begin{definition}[Induced Paths] \label{def:inducedpaths}
Given a configuration $C$, the set of paths induced
by the configuration $C$ for the packet class $pc$:
\begin{multline*}
\paths^C(pc) = \{\pi=(u_1, v_1)\ldots (u_n, v_n) \mid 
valid(\pi) \wedge \\
u_1 = s_{pc} \wedge v_n= d_{pc} \wedge
\forall i. ~v_i \in \route^C(u_i,\lambda_{pc})\}
\end{multline*}
Given a set of packet classes $PC$, the set of paths
 induced by $C$ is defined as
$\paths^C(PC) = \cup_{pc\in PC} \paths^C(pc)$.
\end{definition}

\subsection{Policy Support} \label{sec:policy}

One of the foremost tasks in network management in enterprise 
and multi-tenant datacenters---i.e., where different entities ("tenants") share the datacenter's 
infrastructure (compute, network etc.)---is programming 
networks to forward traffic in a manner consistent with user- and
application-induced high-level policies for performance and security considerations. 
Unlike SDN, ``traditional'' networks are  heterogeneous and run different kinds of 
protocols, and thus, operators require
 support to enforce and/or optimize different
configuration  structure and properties. We 
classify Zeppelin's policy support  into two categories: 
(1) \emph{path policies}: high-level intents on paths of different traffic classes, and 
(2) \emph{configuration policies}: low-level intents on the deployed router configurations. 

\input{policy}  
\Cref{tab:policysupport} describes 
the common path policies 
supported by \name, particularly suited for operators 
of multi-tenant datacenters and enterprises with diverse 
policies across user groups. 
In our tool, operators can
specify policies in a declarative manner using a high-level 
policy language. 
Given  a set $\Psi$ of
path policies, we say that
a set of paths $\Pi$ is policy-compliant with respect to $\Psi$, 
denoted  $\Pi \models \Psi$,
if the paths in $\Pi$ satisfy all the policies in $\Psi$~\cite{genesis}.


\minisection{Reachability and Waypoints}
This policy enables network communication
between pairs of an tenant entity's virtual instances (VM), 
applications, or hosts.  
The tenant may wish that the flow
between two of her end hosts, or from another tenant, must traverse
specific middleboxes, which we also refer to as ``waypoints''.

\minisection{Isolation} Tenants may require various
Quality-of-Service (QoS) or security guarantees since the 
underlying infrastructure is shared among tenants. In the extreme, a
tenant could require that her flows are not affected in any manner
by any other tenant by strictly isolating the path of the tenant's
flows from others' flows. 

\minisection{Traffic Engineering}
While support for the above policies can be used to satisfy tenant 
requirements, network operators need to 
carefully manage constrained resources. Operators may also want
to balance load on their network infrastructure. This is often done
by optimizing a network-wide objective such as total or maximum
utilization of network links due to traffic induced by all tenants. 

The high-level path policies are enforced by different low-level 
configuration constructs pertaining to routing protocols like OSPF and BGP, 
and ideally, the operator requires support to impose constraints on the structure 
and properties of the deployed configurations. 
\Cref{tab:configpolicysupport} 
describes all the configuration policies supported by \name for hierarchical 
control planes. 
% A configuration $C$ satisfies a set of configuration policies $P$
% if $C$ satisfies every constraint in $P$.
% For each configuration policy 
% we define what it means for  a configuration $C=(T,\Theta,W,LP,IF,SR)$ to satisfy it.

\input{zeppelinPolicy}
\minisection{OSPF Domains and Sizes}
We support a policy which restricts how many OSPF domains 
a configuration might have. This policy is useful for 
avoiding situations resulting in too
many domains in the hierarchical split which can be difficult to
administer. Another policy allows the operator to bound 
the size of each OSPF domain because OSPF does
not scale gracefully with network size.  

\minisection{Resource Constraints} Certain 
	routers may not be suited to run BGP due to resource
	constraints. Thus, the operator can specify what set of 
	routers $B\subseteq V$ are BGP-compatible. 
	

\minisection{Configuration Metrics}
\name provides ways to specify upper bounds on the number of
static routes $sc$ and 
BGP configuration overhead $bc$ which we define as the 
sum of local preference entries and iBGP filters.
While static routes are a powerful tool, 
it is desirable to limit their usage since they
can lead to undesired routing behaviors such as routing loops.
Similarly, it is desirable to limit the number of BGP configurations
since they increase the complexity of the network.
\name can  also try to minimize 
certain expressions over the quantities $sc$, and $bc$---e.g., $max(sc, bc)$. 

\subsection{Synthesis of policy-compliant configurations}
We now define when a configuration $C$ is policy-compliant, present our synthesis problems, and introduce two definition of resilience we will use throughout the paper.
\begin{definition}[Policy-Compliance and Synthesis] \label{def:policycompliance}
	Given a set of path policies $\Psi$ and a set of configuration policies $P$,
	a configuration $C$ is policy-compliant with $(\Psi,P)$,  
	written as $C \models (\Psi,P)$, if the set of
	induced paths satisfies $\Psi$---i.e., $\paths^C(PC) \models \Psi$---and $C$ satisfies the policies in $P$.
	The \emph{configuration synthesis problem} is to find, given $\Psi$ and $P$,
a configuration $C$ that is policy compliant with $(\Psi,P)$.
\end{definition}

Our approach will proceed in two phases,
one of which solves the following sub-problem.  
\begin{definition}[Path-Compliance and Synthesis] \label{def:pathcompliance}
Given configuration policies $P$
and a set of paths $\Pi$ over packet classes $PC$,
	a configuration $C$ is path-compliant with 
	$(\Pi,P)$,
	if $\paths^C(PC)=\Pi$ and $C$ satisfies the policies in $P$.
	The \emph{path-compliance synthesis problem} is to find, given $P$ and $\Pi$,
a configuration $C$ that is path-compliant with $(\Pi,P)$.
\end{definition}

\minisection{1-Resilience metrics}
One of the main goals of this paper is to 
generate configurations that are highly resilient to failures. In this
work, we focus on resilient configurations for single link failures. 
For a packet class $pc$ and configuration $C$, we define 
the set of links \emph{affecting} $pc$ as 
$\links(pc) = \{l \mid \exists \pi \in \paths^C(pc).~l \in \pi  \}$.
For a single failure of a link $l$, a packet class $pc$ is affected 
if only if $l \in \links(pc)$. 
Given a configuration
$C=((V,L), \Theta,W,LP,IF,SR)$ and a link $l\in L$,
we write $C_l$ 
to denote the configuration
$C=((V,L\setminus\{l\}), \Theta,W,LP,IF,SR)$
in which the link $l$ has been removed from the topology.
We present two different resilience metrics 
we will use in the following sections. 

The first metric describes how good a given configuration
is at preserving policy-compliance under an 
arbitrary single link failure. 
The score measures, for each policy $pc$, what percentage of the links affecting $pc$
causes a policy to still hold when failing.
\begin{definition}
The \emph{policy-resilience} score of a configuration 
$C=((V,L), \Theta,W,LP,IF,SR)$
is defined as:
\[
PR(C)=\frac{\sum_{\forall pc} |\{ l \mid l \in \links(pc) ~\wedge~ C_l \models (\Psi_{pc}, P) \}|}
{\sum_{\forall pc} |\links(pc)|}
\]
where $C \models (\Psi_{pc}, P)$ means that $C$ is 
compliant for the set of policies $\Psi_{pc}$ that affect packet class $pc$.
\end{definition}

In general, generating configurations with high policy-resilience is hard,
since there may be only a few paths that satisfy a certain policy.
Therefore, we also consider a second 
more relaxed metric, which describes how 
good a given configuration
is at preserving connectivity
(but not policy compliance) upon a single link failure. 
\begin{definition}
The \emph{connectivity-resilience} 
score of a configuration $C=((V,L), \Theta,W,LP,IF,SR)$
is defined as follows:
\[
CR(C)=\frac{\sum_{\forall pc} |\{ l \mid l \in \links(pc) ~\wedge~\paths^{C_l }(pc) \not= \emptyset  \}|}
{\sum_{\forall pc} |\links(pc)|}
\]
\end{definition}
 
Ideally, operators desire a resilience score of 1 (perfectly resilient for policy-compliance or
preserving connectivity). However, achieving this objective is in practice difficult  
due to the 
increased number of configurations one needs to consider,
and sometimes impossible due to the structure of the network and the nature of policies.
In practice, \name can synthesize configurations 
with high resilience scores and operators can run it to generate different configurations until
a threshold score is crossed. 
%\todo{write resilience metrics here and some text like the following.}
%\kausik{Ideally, the most important metric we want to maximize is resilience---i.e.,
%the number of alternate paths between endpoints.
%However, this metric is too hard to handle as it depends on complex graph properties. 
%In practice, when we want improve resilience, we try to minimize
%the number of filters; we will show that this strategy is effective in our experiments. }

